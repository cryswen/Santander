{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d2a9895dd41d1e76f2393525a460ffa9a0e48f44"
   },
   "source": [
    "https://www.kaggle.com/alexpengxiao/preprocessing-model-averaging-by-xgb-lgb-1-39\n",
    "\n",
    "In this notebook, we preprocessed the data and feed the data to gradient boosting tree models, and got 1.39 on public leaderboard.\n",
    "\n",
    "the workflow is as follows:\n",
    "1. **Data preprocessing**. The purpose of data preprocessing is to achieve higher time/space efficiency. What we did includes round, constant features removal, duplicate features removal, insignificant features removal, etc. The key here is to ensure the preprocessing shall not hurt the accuracy.\n",
    "2. **Feature transform**. The purpose of feature transform is to help the models to better grasp the information in the data, and fight overfitting. What we did includes dropping features which \"live\" on different distributions on training/testing set, adding statistical features, adding low-dimensional representation as features. \n",
    "3. **Modeling**.  We used 2 models: xgboost and lightgbm. We averaged the 2 models for the final prediction.\n",
    "\n",
    "Stay tuned, more update will come. \n",
    "\n",
    "references:\n",
    "* [Distribution of Test vs. Training data](https://www.kaggle.com/nanomathias/distribution-of-test-vs-training-data)\n",
    "* [Ensemble of LGBM and XGB](https://www.kaggle.com/lightsalsa/ensemble-of-lgbm-and-xgb)\n",
    "* [predict house prices-model tuning & ensemble](https://www.kaggle.com/alexpengxiao/predict-house-prices-model-tuning-ensemble)\n",
    "* [Stacked Regressions : Top 4% on LeaderBoard](https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "38cf74c8cb535c9a9a74f025ea963528a552ecc0"
   },
   "source": [
    "**step 1**: load train & test data, drop duplicate columns, round the features to NUM_OF_DECIMALS decimals. here NUM_OF_DECIMALS is a experience value which can be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'test.csv', 'train.csv', 'test.csv.zip', 'train.csv.zip', 'sample_submission.csv.zip', 'sample_submission.csv']\n",
      "256 columns with only 1 value are dropped.\n",
      "6 columns are duplicates and are dropped.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4459, 4730)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "test_ID = test['ID']\n",
    "y_train = train['target']\n",
    "y_train = np.log1p(y_train)\n",
    "\n",
    "train.drop(\"ID\", axis = 1, inplace = True)\n",
    "train.drop(\"target\", axis = 1, inplace = True)\n",
    "test.drop(\"ID\", axis = 1, inplace = True)\n",
    "\n",
    "cols_with_onlyone_val = train.columns[train.nunique() == 1]\n",
    "train.drop(cols_with_onlyone_val.values, axis=1, inplace=True)\n",
    "test.drop(cols_with_onlyone_val.values, axis=1, inplace=True)\n",
    "print(str(len(cols_with_onlyone_val)) + ' columns with only 1 value are dropped.')\n",
    "\n",
    "NUM_OF_DECIMALS = 32\n",
    "train = train.round(NUM_OF_DECIMALS)\n",
    "test = test.round(NUM_OF_DECIMALS)\n",
    "\n",
    "colsToRemove = [] \n",
    "columns = train.columns\n",
    "for i in range(len(columns)-1):\n",
    "    v = train[columns[i]].values\n",
    "    dupCols = []\n",
    "    for j in range(i + 1,len(columns)):\n",
    "        if np.array_equal(v, train[columns[j]].values):\n",
    "            colsToRemove.append(columns[j])\n",
    "train.drop(colsToRemove, axis=1, inplace=True) \n",
    "test.drop(colsToRemove, axis=1, inplace=True) \n",
    "print(str(len(colsToRemove)) + ' columns are duplicates and are dropped.')\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0974c5c28779c696c15344b86e11dee097ffc48a"
   },
   "source": [
    "**step 2**: Select features by importance. here we used a weak RandomForestRegressor to get the feature importance. here we select top NUM_OF_FEATURES important features. NUM_OF_FEATURES here is a hyper parameter that can be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "3fc53e695d5f40074447dc85ea94a196e899a292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSLE score for initial RandomForest model aimed for feature selection is1.5398605334526747\n",
      "The first 1000 important features are selected by RandomForestRegressor.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4459, 1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "\n",
    "NUM_OF_FEATURES = 1000\n",
    "\n",
    "def rmsle(y, pred):\n",
    "    return np.sqrt(np.mean(np.power(y - pred, 2)))\n",
    "\n",
    "x1, x2, y1, y2 = model_selection.train_test_split(train, y_train.values, test_size=0.20, random_state=5)\n",
    "model = ensemble.RandomForestRegressor(n_jobs=-1, random_state=0)\n",
    "model.fit(x1, y1)\n",
    "print('The RMSLE score for initial RandomForest model aimed for feature selection is ' + str(rmsle(y2, model.predict(x2))))\n",
    "\n",
    "col = pd.DataFrame({'importance': model.feature_importances_, 'feature': train.columns}).sort_values(\n",
    "    by=['importance'], ascending=[False])[:NUM_OF_FEATURES]['feature'].values\n",
    "train = train[col]\n",
    "test = test[col]\n",
    "print('The first ' + str(NUM_OF_FEATURES) + ' important features are selected by RandomForestRegressor.')\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af1d686dcafd355df61cfb461d74bc2a864acca0"
   },
   "source": [
    "**step 3**: we try to test the training data and testing data with Kolmogorov-Smirnov test. This is a two-sided test for the null hypothesis that whether 2 independent samples are drawn from the same continuous distribution([see more](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ks_2samp.html)). If a feature has different distributions in training set than in testing set, we should remove this feature since what we learned during training cannot generalize. THRESHOLD_P_VALUE and THRESHOLD_STATISTIC are hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "99daf8d41b26ce2a402dd0a136c5547b727eb124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 columns are significantly different with Kolmogorov-Smirnov test statistic 0.3 and p-value threshold 0.01.\n",
      "0 columns are dropped due to failure of generalization.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4459, 1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "THRESHOLD_P_VALUE = 0.01 #need tuned\n",
    "THRESHOLD_STATISTIC = 0.3 #need tuned\n",
    "diff_cols = []\n",
    "for col in train.columns:\n",
    "    statistic, pvalue = ks_2samp(train[col].values, test[col].values)\n",
    "    if pvalue <= THRESHOLD_P_VALUE and np.abs(statistic) > THRESHOLD_STATISTIC:\n",
    "        diff_cols.append(col)\n",
    "print(str(len(diff_cols)) + ' columns are significantly different with Kolmogorov-Smirnov test statistic ' \n",
    "      + str(THRESHOLD_STATISTIC) + ' and p-value threshold ' + str(THRESHOLD_P_VALUE) + '.')\n",
    "\n",
    "for col in diff_cols:\n",
    "    if col in train.columns:\n",
    "        train.drop(col, axis=1, inplace=True)\n",
    "        test.drop(col, axis=1, inplace=True)\n",
    "print(str(len(diff_cols)) + ' columns are dropped due to failure of generalization.')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be30c9c3bca91f0eadcd1ed349c0e1c5538a3702"
   },
   "source": [
    "**step 4**: We add some additional statistical features to the original features. Moreover, we also added low-dimensional representations as features. NUM_OF_COM is hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "f294c53ebcf38aa7017a73230775d356a514c919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459, 1111)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import random_projection\n",
    "ntrain = len(train)\n",
    "ntest = len(test)\n",
    "# concaten train, test data\n",
    "tmp = pd.concat([train,test])#RandomProjection\n",
    "# percentage of nonezero value rows in train is intepretated as weight for each feature\n",
    "weight = ((train != 0).sum()/len(train)).values\n",
    "\n",
    "tmp_train = train[train!=0]\n",
    "tmp_test = test[test!=0]\n",
    "train[\"weight_count\"] = (tmp_train*weight).sum(axis=1)\n",
    "test[\"weight_count\"] = (tmp_test*weight).sum(axis=1)\n",
    "train[\"count_not0\"] = (train != 0).sum(axis=1)\n",
    "test[\"count_not0\"] = (test != 0).sum(axis=1)\n",
    "\n",
    "train[\"sum\"] = train.sum(axis=1)\n",
    "test[\"sum\"] = test.sum(axis=1)\n",
    "train[\"var\"] = tmp_train.var(axis=1)\n",
    "test[\"var\"] = tmp_test.var(axis=1)\n",
    "train[\"median\"] = tmp_train.median(axis=1)\n",
    "test[\"median\"] = tmp_test.median(axis=1)\n",
    "train[\"mean\"] = tmp_train.mean(axis=1)\n",
    "test[\"mean\"] = tmp_test.mean(axis=1)\n",
    "train[\"std\"] = tmp_train.std(axis=1)\n",
    "test[\"std\"] = tmp_test.std(axis=1)\n",
    "train[\"max\"] = tmp_train.max(axis=1)\n",
    "test[\"max\"] = tmp_test.max(axis=1)\n",
    "train[\"min\"] = tmp_train.min(axis=1)\n",
    "test[\"min\"] = tmp_test.min(axis=1)\n",
    "train[\"skew\"] = tmp_train.skew(axis=1)\n",
    "test[\"skew\"] = tmp_test.skew(axis=1)\n",
    "train[\"kurtosis\"] = tmp_train.kurtosis(axis=1)\n",
    "test[\"kurtosis\"] = tmp_test.kurtosis(axis=1)\n",
    "del(tmp_train)\n",
    "del(tmp_test)\n",
    "\n",
    "# create new features through random projection\n",
    "NUM_OF_COM = 100 #need tuned\n",
    "transformer = random_projection.SparseRandomProjection(n_components = NUM_OF_COM)\n",
    "RP = transformer.fit_transform(tmp)\n",
    "rp = pd.DataFrame(RP)\n",
    "columns = [\"RandomProjection{}\".format(i) for i in range(NUM_OF_COM)]\n",
    "rp.columns = columns\n",
    "rp_train = rp[:ntrain]\n",
    "rp_test = rp[ntrain:]\n",
    "rp_test.index = test.index\n",
    "\n",
    "#concat RandomProjection and raw data\n",
    "train = pd.concat([train,rp_train],axis=1)\n",
    "test = pd.concat([test,rp_test],axis=1)\n",
    "\n",
    "del(rp_train)\n",
    "del(rp_test)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8ecc907903eb1a867d3b7ce335f4186dd6b6f361"
   },
   "source": [
    "**step 5**: Define cross-validation methods and models. xgboost and lightgbm are used as base models. the hyper parameters are already tuned by grid search, here we use them directly. NUM_FOLDS can be treat as hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "2dd9facf3e57034f6231e0c61b29eac66107092e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost score: 1.3599 (0.0622)\n",
      "\n",
      "LGBM score: 1.3500 (0.0529)\n",
      "\n",
      "averaged score: 1.3464 (0.0577)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "#define evaluation method for a given model. we use k-fold cross validation on the training set. \n",
    "#the loss function is root mean square logarithm error between target and prediction\n",
    "#note: train and y_train are feeded as global variables\n",
    "NUM_FOLDS = 5 #need tuned\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(NUM_FOLDS, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)\n",
    "#ensemble method: model averaging\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    # the reason of clone is avoiding affect the original base models\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]  \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([ model.predict(X) for model in self.models_ ])\n",
    "        return np.mean(predictions, axis=1)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.055, colsample_bylevel =0.5, \n",
    "                             gamma=1.5, learning_rate=0.02, max_depth=32, \n",
    "                             objective='reg:linear',booster='gbtree',\n",
    "                             min_child_weight=57, n_estimators=1000, reg_alpha=0, \n",
    "                             reg_lambda = 0.2,eval_metric = 'rmse', subsample=0.7, \n",
    "                             silent=1, n_jobs = -1, early_stopping_rounds = 14,\n",
    "                             random_state =7, nthread = -1)\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=144,\n",
    "                              learning_rate=0.005, n_estimators=720, max_depth=13,\n",
    "                              metric='rmse',is_training_metric=True,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,verbose=-1,\n",
    "                              bagging_freq = 5, feature_fraction = 0.9) \n",
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\" .format(score.mean(), score.std()))\n",
    "averaged_models = AveragingModels(models = (model_xgb, model_lgb))\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\"averaged score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98db14d0a809d8267964e4f303b0fa377ae792a3"
   },
   "source": [
    "**step 6**: average the two base models and submit the final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa1fedd6673d5781b2ed735382d898e21cdd952a"
   },
   "outputs": [],
   "source": [
    "averaged_models.fit(train.values, y_train)\n",
    "pred = np.expm1(averaged_models.predict(test.values))\n",
    "ensemble = pred\n",
    "sub = pd.DataFrame()\n",
    "sub['ID'] = test_ID\n",
    "sub['target'] = ensemble\n",
    "sub.to_csv('../output/submission_avgxgblgbm2.csv',index=False)\n",
    "\n",
    "# submission_avgxgblgbm.csv\n",
    "# Xgboost score: 1.3611 (0.0637)\n",
    "# LGBM score: 1.3500 (0.0529)\n",
    "# averaged score: 1.3473 (0.0586)\n",
    "# submission score: 1.40\n",
    "\n",
    "# submission_avgxgblgbm2.csv\n",
    "# Xgboost score: 1.3599 (0.0622)\n",
    "# LGBM score: 1.3500 (0.0529)\n",
    "# averaged score: 1.3464 (0.0577)\n",
    "# submission score: 1.40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/nanomathias/feature-engineering-benchmarks\n",
    "\n",
    "Feature Engineering Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_df = pd.DataFrame()\n",
    "\n",
    "# Wrapper function\n",
    "def diff2(x):\n",
    "    return np.diff(x, n=2)\n",
    "\n",
    "# Different pre-processing to be used before each primary function\n",
    "preprocess_steps = [\n",
    "    [],\n",
    "    [np.diff], [diff2],\n",
    "    [np.unique], [np.unique, np.diff], [np.unique, diff2]    \n",
    "]\n",
    "\n",
    "# Different statistics to calculate on each preprocessed step\n",
    "stats = [len, np.min, np.max, np.median, np.std, skew, kurtosis] + 19 * [np.percentile]\n",
    "stats_kwargs = [{} for i in range(7)] + [{'q': np.round(i, 2)} for i in np.linspace(0.05, 0.95, 19)]\n",
    "\n",
    "# Only operate on non-nulls\n",
    "for funs in preprocess_steps:\n",
    "    \n",
    "    # Apply pre-processing steps\n",
    "    x = total_df[total_df != 0]\n",
    "    for f in funs:\n",
    "        x = f(x)\n",
    "        \n",
    "    # Go through our set of stat functions\n",
    "    for stat, stat_kwargs in zip(stats, stats_kwargs):\n",
    "        \n",
    "        # Construct feature name\n",
    "        name_components = [\n",
    "            stat.__name__,\n",
    "            \"_\".join([f.__name__ for f in funs]),\n",
    "            \"_\".join([\"{}={}\".format(k, v) for k,v in stat_kwargs.items()])\n",
    "        ]\n",
    "        feature_name = \"-\".join([e for e in name_components if e])\n",
    "\n",
    "        # Calc and save new feature in our dataframe\n",
    "        aggregate_df[feature_name] = total_df.apply(lambda x: stat(x, **stat_kwargs), axis=1)\n",
    "        \n",
    "# Extra features\n",
    "aggregate_df['number_of_different'] = total_df.nunique(axis=1)\n",
    "aggregate_df['non_zero_count'] = total_df.astype(bool).sum(axis=1) \n",
    "aggregate_df['sum_zeros'] = (total_df == 0).astype(int).sum(axis=1)\n",
    "aggregate_df['non_zero_fraction'] = total_df.shape[1] / total_df.astype(bool).sum(axis=1) \n",
    "aggregate_df['geometric_mean'] = total_df.apply(\n",
    "    lambda x: np.exp(np.log(x[x>0]).mean()), axis=1\n",
    ")\n",
    "aggregate_df.reset_index(drop=True, inplace=True)\n",
    "aggregate_df['geometric_mean'] = aggregate_df['geometric_mean'].replace(np.nan, 0)\n",
    "aggregate_df['non_zero_fraction'] = aggregate_df['non_zero_fraction'].replace(np.inf, 0)\n",
    "\n",
    "# Show user which aggregates were created\n",
    "print(f\">> Created {len(aggregate_df.columns)} features for; {aggregate_df.columns.tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
